/**
 * Voice Message Processor for Telegram Bot
 * 
 * Full pipeline:
 * 1. Download voice from Telegram
 * 2. Save to cloud storage
 * 3. Transcribe speech to text
 * 4. Detect melody (if hummed/sung) via MIDI transcription
 * 5. Format for Suno API compatibility
 */

import { createClient } from 'https://esm.sh/@supabase/supabase-js@2.39.3';
import { BOT_CONFIG } from '../config.ts';
import { sendMessage, editMessageText, deleteMessage } from '../telegram-api.ts';
import { escapeMarkdown, trackMetric } from '../utils/index.ts';
import { createLogger } from '../../_shared/logger.ts';
import { setActiveMenuMessageId, deleteActiveMenu } from '../core/active-menu-manager.ts';

const logger = createLogger('voice-processor');

const supabase = createClient(
  BOT_CONFIG.supabaseUrl,
  BOT_CONFIG.supabaseServiceKey
);

interface TelegramVoice {
  file_id: string;
  file_unique_id: string;
  duration: number;
  mime_type?: string;
  file_size?: number;
}

interface VoiceProcessingResult {
  success: boolean;
  referenceId?: string;
  fileUrl?: string;
  transcription?: string;
  hasMelody?: boolean;
  midiUrl?: string;
  notes?: Array<{ pitch: number; startTime: number; endTime: number }>;
  error?: string;
}

/**
 * Process voice message with full pipeline:
 * - Cloud storage
 * - Speech transcription
 * - Melody detection
 * - Suno format preparation
 */
export async function processVoiceMessage(
  chatId: number,
  userId: number,
  voice: TelegramVoice
): Promise<VoiceProcessingResult> {
  const startTime = Date.now();
  let progressMessageId: number | undefined;

  try {
    // Delete any active menu
    await deleteActiveMenu(userId, chatId);

    // Get user profile
    const { data: profile } = await supabase
      .from('profiles')
      .select('user_id, language_code')
      .eq('telegram_id', userId)
      .single();

    if (!profile) {
      await sendMessage(chatId, '‚ùå –ü—Ä–æ—Ñ–∏–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω\\. –û—Ç–∫—Ä–æ–π—Ç–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏\\.');
      return { success: false, error: 'Profile not found' };
    }

    // Check voice duration (max 5 min for melody, max 60s for transcription)
    if (voice.duration > 300) {
      await sendMessage(chatId, '‚ö†Ô∏è –ì–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–æ–µ\\. –ú–∞–∫—Å–∏–º—É–º 5 –º–∏–Ω—É—Ç\\.');
      return { success: false, error: 'Duration too long' };
    }

    // Send initial progress
    const progressMsg = await sendMessage(
      chatId,
      'üé§ *–û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ\\.\\.\\.*\n\n' +
        '‚ñì‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 5%\n' +
        '‚è≥ –ó–∞–≥—Ä—É–∂–∞—é –≤ –æ–±–ª–∞–∫–æ\\.\\.\\.'
    );
    progressMessageId = progressMsg?.result?.message_id;

    // Get file URL from Telegram
    const fileUrl = await getFileUrl(voice.file_id);
    if (!fileUrl) {
      if (progressMessageId) {
        await editMessageText(chatId, progressMessageId, '‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ñ–∞–π–ª\\.');
      }
      return { success: false, error: 'Failed to get file' };
    }

    // Download voice file
    const audioResponse = await fetch(fileUrl);
    if (!audioResponse.ok) {
      throw new Error('Failed to download voice from Telegram');
    }

    // IMPORTANT: Response body can only be consumed once, so use arrayBuffer first
    // and create Blob from it if needed
    const audioBuffer = await audioResponse.arrayBuffer();

    // Update progress
    if (progressMessageId) {
      await editMessageText(
        chatId,
        progressMessageId,
        'üé§ *–ó–∞–≥—Ä—É–∂–∞—é –≤ –æ–±–ª–∞–∫–æ\\.\\.\\.*\n\n' +
          '‚ñì‚ñì‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 20%\n' +
          '‚òÅÔ∏è –°–æ—Ö—Ä–∞–Ω—è—é –∞—É–¥–∏–æ\\.\\.\\.'
      );
    }

    // Upload to cloud storage (OGG format from Telegram)
    const timestamp = Date.now();
    const storagePath = `${profile.user_id}/voice-messages/voice_${timestamp}.ogg`;

    const { error: uploadError } = await supabase.storage
      .from('reference-audio')
      .upload(storagePath, new Uint8Array(audioBuffer), {
        contentType: 'audio/ogg',
        upsert: false,
      });

    if (uploadError) {
      logger.error('Cloud upload error', uploadError);
      throw new Error('Failed to upload to cloud');
    }

    // Get public URL
    const {
      data: { publicUrl },
    } = supabase.storage.from('reference-audio').getPublicUrl(storagePath);

    logger.info('Voice uploaded to storage', { storagePath, publicUrl });

    // Update progress
    if (progressMessageId) {
      await editMessageText(
        chatId,
        progressMessageId,
        'üé§ *–†–∞—Å–ø–æ–∑–Ω–∞—é —Ä–µ—á—å\\.\\.\\.*\n\n' +
          '‚ñì‚ñì‚ñì‚ñì‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 40%\n' +
          'üó£Ô∏è –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É—é –∞—É–¥–∏–æ\\.\\.\\.'
      );
    }

    // Transcribe speech (for short voice messages)
    let transcription: string | undefined;
    if (voice.duration <= 60) {
      try {
        const base64Audio = arrayBufferToBase64(audioBuffer);
        
        const { data: transcriptData, error: transcriptError } = await supabase.functions.invoke(
          'speech-to-text',
          {
            body: {
              audio: base64Audio,
              language: profile.language_code || 'ru',
            },
          }
        );

        if (!transcriptError && transcriptData?.text) {
          transcription = transcriptData.text.trim();
          logger.info('Transcription successful', { length: transcription?.length || 0 });
        }
      } catch (e) {
        logger.error('Transcription failed', e);
        // Continue without transcription
      }
    }

    // Update progress
    if (progressMessageId) {
      await editMessageText(
        chatId,
        progressMessageId,
        'üé§ *–ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –º–µ–ª–æ–¥–∏—é\\.\\.\\.*\n\n' +
          '‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñë‚ñë‚ñë‚ñë 60%\n' +
          'üéµ –ò—â—É –Ω–æ—Ç—ã –∏ –º–µ–ª–æ–¥–∏—é\\.\\.\\.'
      );
    }

    // Detect melody via MIDI transcription (for longer recordings or humming)
    let hasMelody = false;
    let midiUrl: string | undefined;
    let notes: Array<{ pitch: number; startTime: number; endTime: number }> | undefined;

    try {
      const { data: midiData, error: midiError } = await supabase.functions.invoke(
        'replicate-midi-transcription',
        {
          body: {
            audioUrl: publicUrl,
            model: 'basic-pitch',
          },
        }
      );

      if (!midiError && midiData?.success) {
        hasMelody = midiData.notes_count > 10; // Consider melody if >10 notes
        midiUrl = midiData.midiUrl;
        notes = midiData.notes;
        logger.info('Melody detection result', { 
          notesCount: midiData.notes_count, 
          hasMelody 
        });
      }
    } catch (e) {
      logger.error('Melody detection failed', e);
      // Continue without melody
    }

    // Update progress
    if (progressMessageId) {
      await editMessageText(
        chatId,
        progressMessageId,
        'üé§ *–°–æ—Ö—Ä–∞–Ω—è—é —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\\.\\.\\.*\n\n' +
          '‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñë‚ñë 80%\n' +
          'üíæ –ó–∞–ø–∏—Å—ã–≤–∞—é –≤ –±–∞–∑—É\\.\\.\\.'
      );
    }

    // Save to reference_audio table
    const { data: savedRef, error: dbError } = await supabase
      .from('reference_audio')
      .insert({
        user_id: profile.user_id,
        file_name: `–ì–æ–ª–æ—Å–æ–≤–æ–µ ${new Date().toLocaleDateString('ru-RU')}`,
        file_url: publicUrl,
        file_size: voice.file_size,
        mime_type: 'audio/ogg',
        duration_seconds: voice.duration,
        source: 'telegram_voice',
        transcription: transcription,
        has_vocals: !!transcription,
        has_instrumentals: hasMelody,
        analysis_status: 'completed',
        analyzed_at: new Date().toISOString(),
        metadata: {
          telegram_file_id: voice.file_id,
          midi_url: midiUrl,
          notes_count: notes?.length || 0,
          has_melody: hasMelody,
        },
      })
      .select('id')
      .single();

    if (dbError) {
      logger.error('Error saving voice reference', dbError);
    }

    // Delete progress message
    if (progressMessageId) {
      try {
        await deleteMessage(chatId, progressMessageId);
      } catch (e) {
        /* ignore */
      }
    }

    // Build result message
    let resultText = `‚úÖ *–ì–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ\\!*\n\n`;
    resultText += `‚è± –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: ${formatDuration(voice.duration)}\n`;

    if (transcription) {
      const preview = transcription.substring(0, 150);
      resultText += `\nüìù *–†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç:*\n`;
      resultText += `>${escapeMarkdown(preview)}${transcription.length > 150 ? '\\.\\.\\.' : ''}\n`;
    }

    if (hasMelody && notes) {
      resultText += `\nüéµ *–û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –º–µ–ª–æ–¥–∏—è\\!*\n`;
      resultText += `>üéπ –ù–æ—Ç: ${notes.length}\n`;
      
      // Calculate pitch range
      if (notes.length > 0) {
        const pitches = notes.map(n => n.pitch);
        const minPitch = Math.min(...pitches);
        const maxPitch = Math.max(...pitches);
        resultText += `>üéº –î–∏–∞–ø–∞–∑–æ–Ω: ${midiNoteToName(minPitch)} \\- ${midiNoteToName(maxPitch)}\n`;
      }
    }

    // Simplified action keyboard - Cover/Extend only available in app interface
    const keyboard: Array<Array<{ text: string; callback_data?: string; web_app?: { url: string } }>> = [];

    // Build deeplink with reference ID if available
    const deeplink = savedRef?.id 
      ? `${BOT_CONFIG.miniAppUrl}?startapp=ref_${savedRef.id}`
      : `${BOT_CONFIG.miniAppUrl}?startapp=cloud`;

    // Main action - open in app
    keyboard.push([
      { text: 'üì± –û—Ç–∫—Ä—ã—Ç—å –≤ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–∏', web_app: { url: deeplink } },
    ]);

    // Menu button
    keyboard.push([
      { text: 'üìã –ú–µ–Ω—é', callback_data: 'main_menu' },
    ]);

    // Send result message
    const resultMsg = await sendMessage(chatId, resultText, { inline_keyboard: keyboard });
    if (resultMsg?.result?.message_id) {
      await setActiveMenuMessageId(userId, chatId, resultMsg.result.message_id, 'voice_result');
    }

    // Track metrics
    trackMetric({
      eventType: 'voice_transcribed',
      success: true,
      telegramChatId: chatId,
      responseTimeMs: Date.now() - startTime,
      metadata: {
        duration: voice.duration,
        hasTranscription: !!transcription,
        hasMelody,
        notesCount: notes?.length || 0,
        referenceId: savedRef?.id,
      },
    });

    return {
      success: true,
      referenceId: savedRef?.id,
      fileUrl: publicUrl,
      transcription,
      hasMelody,
      midiUrl,
      notes,
    };
  } catch (error) {
    logger.error('Error processing voice message', error);

    if (progressMessageId) {
      await editMessageText(chatId, progressMessageId, '‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è\\.');
    } else {
      await sendMessage(chatId, '‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è\\.');
    }

    trackMetric({
      eventType: 'voice_transcription_failed',
      success: false,
      telegramChatId: chatId,
      errorMessage: error instanceof Error ? error.message : String(error),
      responseTimeMs: Date.now() - startTime,
    });

    return { success: false, error: error instanceof Error ? error.message : String(error) };
  }
}

/**
 * Handle voice message callbacks
 */
export async function handleVoiceProcessorCallback(
  data: string,
  chatId: number,
  userId: number,
  messageId: number,
  queryId: string
): Promise<boolean> {
  const { answerCallbackQuery } = await import('../telegram-api.ts');

  try {
    // Generate track from voice transcription
    if (data.startsWith('voice_to_track_')) {
      const refId = data.replace('voice_to_track_', '');
      await handleVoiceToTrack(chatId, userId, refId, messageId);
      await answerCallbackQuery(queryId, 'üéµ –ù–∞—á–∏–Ω–∞—é –≥–µ–Ω–µ—Ä–∞—Ü–∏—é!');
      return true;
    }

    // Edit text
    if (data.startsWith('voice_edit_text_')) {
      await editMessageText(
        chatId,
        messageId,
        '‚úèÔ∏è *–†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞*\n\n' +
          '–û—Ç–ø—Ä–∞–≤—å—Ç–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏\\.\n\n' +
          '–ò–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ /cancel –¥–ª—è –æ—Ç–º–µ–Ω—ã\\.'
      );
      await answerCallbackQuery(queryId);
      return true;
    }

    // Download MIDI
    if (data.startsWith('voice_download_midi_')) {
      const refId = data.replace('voice_download_midi_', '');
      await handleDownloadMidi(chatId, refId);
      await answerCallbackQuery(queryId, 'üì• –û—Ç–ø—Ä–∞–≤–ª—è—é MIDI —Ñ–∞–π–ª');
      return true;
    }

    // Create arrangement from melody
    if (data.startsWith('voice_to_arrangement_')) {
      const refId = data.replace('voice_to_arrangement_', '');
      await handleVoiceToArrangement(chatId, userId, refId, messageId);
      await answerCallbackQuery(queryId, 'üé∏ –°–æ–∑–¥–∞—é –∞—Ä–∞–Ω–∂–∏—Ä–æ–≤–∫—É!');
      return true;
    }

    // Create cover
    if (data.startsWith('voice_to_cover_')) {
      const refId = data.replace('voice_to_cover_', '');
      await handleVoiceToCover(chatId, userId, refId, messageId);
      await answerCallbackQuery(queryId, 'üé§ –ì–æ—Ç–æ–≤–ª—é –∫–∞–≤–µ—Ä!');
      return true;
    }

    // Separate stems
    if (data.startsWith('voice_to_stems_')) {
      const refId = data.replace('voice_to_stems_', '');
      await handleVoiceToStems(chatId, userId, refId, messageId);
      await answerCallbackQuery(queryId, 'üéõÔ∏è –†–∞–∑–¥–µ–ª—è—é –Ω–∞ —Å—Ç–µ–º—ã!');
      return true;
    }

    return false;
  } catch (error) {
    logger.error('Error handling voice callback', error);
    await answerCallbackQuery(queryId, '–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞');
    return false;
  }
}

// Handler implementations
async function handleVoiceToTrack(
  chatId: number,
  userId: number,
  refId: string,
  messageId: number
): Promise<void> {
  const { data: ref } = await supabase
    .from('reference_audio')
    .select('transcription, file_url')
    .eq('id', refId)
    .single();

  if (!ref?.transcription) {
    await editMessageText(chatId, messageId, '‚ùå –¢–µ–∫—Å—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω\\.');
    return;
  }

  const { data: profile } = await supabase
    .from('profiles')
    .select('user_id')
    .eq('telegram_id', userId)
    .single();

  if (!profile) {
    await editMessageText(chatId, messageId, '‚ùå –ü—Ä–æ—Ñ–∏–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω\\.');
    return;
  }

  await editMessageText(
    chatId,
    messageId,
    'üéµ *–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –Ω–∞—á–∞—Ç–∞\\!*\n\n' +
      `üìù ${escapeMarkdown(ref.transcription.substring(0, 100))}${ref.transcription.length > 100 ? '\\.\\.\\.' : ''}\n\n` +
      '‚è≥ –û–±—ã—á–Ω–æ –∑–∞–Ω–∏–º–∞–µ—Ç 1\\-3 –º–∏–Ω—É—Ç—ã\\.\n' +
      'üîî –í—ã –ø–æ–ª—É—á–∏—Ç–µ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ\\!'
  );

  // Start generation
  await supabase.functions.invoke('suno-generate', {
    body: {
      prompt: ref.transcription,
      userId: profile.user_id,
      instrumental: false,
      source: 'telegram_voice',
      chatId,
      messageId,
    },
  });
}

async function handleDownloadMidi(chatId: number, refId: string): Promise<void> {
  const { data: ref } = await supabase
    .from('reference_audio')
    .select('metadata, file_name')
    .eq('id', refId)
    .single();

  const midiUrl = (ref?.metadata as any)?.midi_url;
  if (!midiUrl) {
    await sendMessage(chatId, '‚ùå MIDI —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω\\.');
    return;
  }

  // Send MIDI file as document via URL
  await sendMessage(chatId, `üéπ *MIDI —Ñ–∞–π–ª:*\n\n[–°–∫–∞—á–∞—Ç—å MIDI](${escapeMarkdown(midiUrl)})`, {
    inline_keyboard: [[{ text: 'üì• –°–∫–∞—á–∞—Ç—å MIDI', url: midiUrl }]]
  });
}

async function handleVoiceToArrangement(
  chatId: number,
  userId: number,
  refId: string,
  messageId: number
): Promise<void> {
  const { data: ref } = await supabase
    .from('reference_audio')
    .select('metadata, file_url')
    .eq('id', refId)
    .single();

  if (!ref) {
    await editMessageText(chatId, messageId, '‚ùå –†–µ—Ñ–µ—Ä–µ–Ω—Å –Ω–µ –Ω–∞–π–¥–µ–Ω\\.');
    return;
  }

  await editMessageText(
    chatId,
    messageId,
    'üé∏ *–°–æ–∑–¥–∞—é –∞—Ä–∞–Ω–∂–∏—Ä–æ–≤–∫—É –Ω–∞ –æ—Å–Ω–æ–≤–µ –º–µ–ª–æ–¥–∏–∏\\.\\.\\.*\n\n' +
      '‚è≥ –≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç\\.'
  );

  // Trigger arrangement generation via cover with melody weight
  const { data: profile } = await supabase
    .from('profiles')
    .select('user_id')
    .eq('telegram_id', userId)
    .single();

  if (profile) {
    await supabase.functions.invoke('suno-remix', {
      body: {
        audioUrl: ref.file_url,
        userId: profile.user_id,
        prompt: 'Create a full arrangement based on this melody',
        audioWeight: 0.8, // High weight to preserve melody
        source: 'telegram_voice_arrangement',
        chatId,
      },
    });
  }
}

async function handleVoiceToCover(
  chatId: number,
  userId: number,
  refId: string,
  messageId: number
): Promise<void> {
  const { data: ref } = await supabase
    .from('reference_audio')
    .select('file_url')
    .eq('id', refId)
    .single();

  if (!ref) {
    await editMessageText(chatId, messageId, '‚ùå –†–µ—Ñ–µ—Ä–µ–Ω—Å –Ω–µ –Ω–∞–π–¥–µ–Ω\\.');
    return;
  }

  const { data: profile } = await supabase
    .from('profiles')
    .select('user_id')
    .eq('telegram_id', userId)
    .single();

  if (!profile) {
    await editMessageText(chatId, messageId, '‚ùå –ü—Ä–æ—Ñ–∏–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω\\.');
    return;
  }

  await editMessageText(
    chatId,
    messageId,
    'üé§ *–°–æ–∑–¥–∞—é –∫–∞–≤–µ—Ä\\.\\.\\.*\n\n' +
      '‚è≥ –û–±—ã—á–Ω–æ –∑–∞–Ω–∏–º–∞–µ—Ç 2\\-4 –º–∏–Ω—É—Ç—ã\\.'
  );

  await supabase.functions.invoke('suno-remix', {
    body: {
      audioUrl: ref.file_url,
      userId: profile.user_id,
      prompt: 'Create a cover version',
      audioWeight: 0.5,
      source: 'telegram_voice_cover',
      chatId,
    },
  });
}

async function handleVoiceToStems(
  chatId: number,
  userId: number,
  refId: string,
  messageId: number
): Promise<void> {
  const { data: ref } = await supabase
    .from('reference_audio')
    .select('file_url')
    .eq('id', refId)
    .single();

  if (!ref) {
    await editMessageText(chatId, messageId, '‚ùå –†–µ—Ñ–µ—Ä–µ–Ω—Å –Ω–µ –Ω–∞–π–¥–µ–Ω\\.');
    return;
  }

  const { data: profile } = await supabase
    .from('profiles')
    .select('user_id')
    .eq('telegram_id', userId)
    .single();

  if (!profile) {
    await editMessageText(chatId, messageId, '‚ùå –ü—Ä–æ—Ñ–∏–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω\\.');
    return;
  }

  await editMessageText(
    chatId,
    messageId,
    'üéõÔ∏è *–†–∞–∑–¥–µ–ª—è—é –Ω–∞ —Å—Ç–µ–º—ã\\.\\.\\.*\n\n' +
      '‚è≥ –û–±—ã—á–Ω–æ –∑–∞–Ω–∏–º–∞–µ—Ç 1\\-2 –º–∏–Ω—É—Ç—ã\\.'
  );

  await supabase.functions.invoke('suno-separate-vocals', {
    body: {
      audioUrl: ref.file_url,
      userId: profile.user_id,
      source: 'telegram_voice_stems',
      chatId,
    },
  });
}

// Utility functions
async function getFileUrl(fileId: string): Promise<string | null> {
  try {
    const response = await fetch(
      `https://api.telegram.org/bot${BOT_CONFIG.botToken}/getFile?file_id=${fileId}`
    );

    const data = await response.json();

    if (!data.ok || !data.result?.file_path) {
      return null;
    }

    return `https://api.telegram.org/file/bot${BOT_CONFIG.botToken}/${data.result.file_path}`;
  } catch (error) {
    logger.error('Error getting file URL', error);
    return null;
  }
}

function arrayBufferToBase64(buffer: ArrayBuffer): string {
  const uint8Array = new Uint8Array(buffer);
  const chunkSize = 0x8000;
  let binary = '';
  
  for (let i = 0; i < uint8Array.length; i += chunkSize) {
    const chunk = uint8Array.subarray(i, Math.min(i + chunkSize, uint8Array.length));
    binary += String.fromCharCode.apply(null, Array.from(chunk));
  }
  
  return btoa(binary);
}

function formatDuration(seconds: number): string {
  const mins = Math.floor(seconds / 60);
  const secs = seconds % 60;
  return mins > 0 ? `${mins}:${secs.toString().padStart(2, '0')}` : `${secs}—Å`;
}

function midiNoteToName(note: number): string {
  const noteNames = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B'];
  const octave = Math.floor(note / 12) - 1;
  const noteName = noteNames[note % 12];
  return `${noteName}${octave}`;
}
